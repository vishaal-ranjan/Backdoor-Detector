{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CybersecProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyqfp4buHuyi"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "torch.set_printoptions(linewidth=120)\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peYJ8zsFcAQH"
      },
      "source": [
        "num_workers = 0\n",
        "batch_size = 20\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhqVAeBnXw7Q",
        "outputId": "2795c2b8-6e38-46e7-a9eb-9f9c118f1d4f"
      },
      "source": [
        "train_loader.dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdjQNKr9Ka41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a089a5-5f80-4a3b-882b-e0c6c5344376"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1) \n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0)\n",
        "        self.dropout2 = nn.Dropout2d(0)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "model = Net()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (dropout1): Dropout2d(p=0, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_m9TILcXn2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b31bd3-6a5f-4027-8b1e-e1914ab57666"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "n_epochs = 1\n",
        "model.train()\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "confidence = list(0. for i in range(10)) \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    \n",
        "    for data, target in train_loader:\n",
        "        data=data.to(device)\n",
        "        target=target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        a, pred = torch.max(output, 1)\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        count=0\n",
        "        for i in range(batch_size):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "            if a[count].item()<=confidence[label]:\n",
        "              confidence[label]=a[count].item()\n",
        "            count+=1\n",
        "\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss\n",
        "        ))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.150676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (dropout1): Dropout2d(p=0, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBn8TH1D2Ke3",
        "outputId": "767a8031-8bd9-4051-a78d-fb9ac1f510c2"
      },
      "source": [
        "confidence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-2.215944766998291,\n",
              " -2.2253644466400146,\n",
              " -2.2421669960021973,\n",
              " -2.222172498703003,\n",
              " -2.231606960296631,\n",
              " -2.228450298309326,\n",
              " -2.2422738075256348,\n",
              " -2.2339107990264893,\n",
              " -2.2306504249572754,\n",
              " -2.2370591163635254]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVQcOnuXkqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543a2c27-436e-4870-f7ef-707369b4af97"
      },
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(11))\n",
        "class_total = list(0. for i in range(11))\n",
        "model.eval() \n",
        "\n",
        "for data, target in test_loader:\n",
        "    data=data.to(device)\n",
        "    target=target.to(device)\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    a, pred = torch.max(output, 1)\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.063188\n",
            "\n",
            "Test Accuracy of     0: 99% (971/980)\n",
            "Test Accuracy of     1: 99% (1130/1135)\n",
            "Test Accuracy of     2: 98% (1015/1032)\n",
            "Test Accuracy of     3: 98% (996/1010)\n",
            "Test Accuracy of     4: 97% (961/982)\n",
            "Test Accuracy of     5: 99% (888/892)\n",
            "Test Accuracy of     6: 96% (920/958)\n",
            "Test Accuracy of     7: 96% (989/1028)\n",
            "Test Accuracy of     8: 96% (941/974)\n",
            "Test Accuracy of     9: 97% (988/1009)\n",
            "\n",
            "Test Accuracy (Overall): 97% (9799/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS9A-hk6NQ_i",
        "outputId": "aaeea1fe-8ab3-4a20-c2bb-3d23a443c04b"
      },
      "source": [
        "class_correct = list(0. for i in range(11))\n",
        "class_total = list(0. for i in range(11))\n",
        "for data, target in test_loader:\n",
        "    data=data.to(device)\n",
        "    target=target.to(device)\n",
        "    output = model(data)\n",
        "    #print(target)\n",
        "    a, pred = torch.max(output, 1)\n",
        "    print(a)\n",
        "    print(target)\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    count=0\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "        if a[count].item()<=min(confidence):\n",
        "          class_correct[10] += correct[i].item()\n",
        "          class_total[10] += 1\n",
        "        count+=1\n",
        "    \n",
        "    break\n",
        "#print(pred)\n",
        "#print(target)\n",
        "print(class_correct)\n",
        "print(confidence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.2173e-05, -3.8147e-06, -1.6925e-03, -2.9563e-05, -2.5868e-05, -1.4808e-03, -1.5727e-03, -3.5926e-03,\n",
            "        -1.2164e-01, -3.0401e-03, -1.1921e-07, -1.0014e-05, -1.5974e-05, -5.9605e-07, -5.1139e-05, -3.0167e-04,\n",
            "        -9.5840e-05, -3.6007e-04, -9.5398e-01, -2.1458e-06], device='cuda:0', grad_fn=<MaxBackward0>)\n",
            "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4], device='cuda:0')\n",
            "[3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 4.0, 0.0]\n",
            "[-1.4688225984573364, -1.0965884923934937, -1.2206205129623413, -1.269418716430664, -1.0011956691741943, -1.2658755779266357, -0.9875769019126892, -1.0830365419387817, -1.156612753868103, -1.176843285560608]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}